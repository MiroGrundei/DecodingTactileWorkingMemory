{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-06T11:51:16.103107500Z",
     "start_time": "2025-05-06T11:51:14.406974500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 valid logs found for sub-2000, session 0\n",
      "4 valid logs found for sub-2000, session 1\n",
      "4 valid logs found for sub-2000, session 2\n",
      "2 valid logs found for sub-2002, session 0\n",
      "4 valid logs found for sub-2002, session 1\n",
      "4 valid logs found for sub-2002, session 2\n",
      "1 valid logs found for sub-2003, session 0\n",
      "4 valid logs found for sub-2003, session 1\n",
      "4 valid logs found for sub-2003, session 2\n",
      "1 valid logs found for sub-2005, session 0\n",
      "4 valid logs found for sub-2005, session 1\n",
      "4 valid logs found for sub-2005, session 2\n",
      "1 valid logs found for sub-2006, session 0\n",
      "4 valid logs found for sub-2006, session 1\n",
      "4 valid logs found for sub-2006, session 2\n",
      "1 valid logs found for sub-2007, session 0\n",
      "4 valid logs found for sub-2007, session 1\n",
      "4 valid logs found for sub-2007, session 2\n",
      "1 valid logs found for sub-2009, session 0\n",
      "4 valid logs found for sub-2009, session 1\n",
      "4 valid logs found for sub-2009, session 2\n",
      "1 valid logs found for sub-2010, session 0\n",
      "4 valid logs found for sub-2010, session 1\n",
      "4 valid logs found for sub-2010, session 2\n",
      "1 valid logs found for sub-2011, session 0\n",
      "4 valid logs found for sub-2011, session 1\n",
      "4 valid logs found for sub-2011, session 2\n",
      "1 valid logs found for sub-2012, session 0\n",
      "4 valid logs found for sub-2012, session 1\n",
      "4 valid logs found for sub-2012, session 2\n",
      "1 valid logs found for sub-2013, session 0\n",
      "4 valid logs found for sub-2013, session 1\n",
      "4 valid logs found for sub-2013, session 2\n",
      "1 valid logs found for sub-2015, session 0\n",
      "4 valid logs found for sub-2015, session 1\n",
      "4 valid logs found for sub-2015, session 2\n",
      "1 valid logs found for sub-2017, session 0\n",
      "4 valid logs found for sub-2017, session 1\n",
      "4 valid logs found for sub-2017, session 2\n",
      "1 valid logs found for sub-2018, session 0\n",
      "4 valid logs found for sub-2018, session 1\n",
      "4 valid logs found for sub-2018, session 2\n",
      "2 valid logs found for sub-2019, session 0\n",
      "4 valid logs found for sub-2019, session 1\n",
      "4 valid logs found for sub-2019, session 2\n",
      "1 valid logs found for sub-2020, session 0\n",
      "4 valid logs found for sub-2020, session 1\n",
      "4 valid logs found for sub-2020, session 2\n",
      "1 valid logs found for sub-2021, session 0\n",
      "4 valid logs found for sub-2021, session 1\n",
      "4 valid logs found for sub-2021, session 2\n",
      "1 valid logs found for sub-2023, session 0\n",
      "4 valid logs found for sub-2023, session 1\n",
      "4 valid logs found for sub-2023, session 2\n",
      "1 valid logs found for sub-2024, session 0\n",
      "4 valid logs found for sub-2024, session 1\n",
      "4 valid logs found for sub-2024, session 2\n",
      "\n",
      "Behavioral data written to: E:\\MeMoSLAP\\data\\behav_data.tsv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pingouin as pg\n",
    "\n",
    "# Extract behavioral data from log files\n",
    "\n",
    "# Define paths\n",
    "src_dir = r'E:\\MeMoSLAP\\data\\logs_task'\n",
    "output_file = r'E:\\MeMoSLAP\\data\\behav_data.tsv'\n",
    "\n",
    "# Define subject IDs\n",
    "subject_nums = [0, 2, 3, 5, 6, 7, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 21, 23, 24]\n",
    "subjects = [f'sub-20{num:02}' for num in subject_nums]\n",
    "\n",
    "results = []\n",
    "\n",
    "# Process each subject\n",
    "for subject in subjects:\n",
    "    for session in [0, 1, 2]:\n",
    "        # Construct session directory and filename pattern\n",
    "        if session == 0:\n",
    "            session_dir = os.path.join(src_dir, f'{subject}_ses-base')\n",
    "            pattern = f'{subject}_tDCS_TWMD_ses-baseline'\n",
    "        else:\n",
    "            session_dir = os.path.join(src_dir, f'{subject}_ses-task')\n",
    "            pattern = f'{subject}_tDCS_TWMD_ses-{session:02d}'\n",
    "\n",
    "        if not os.path.exists(session_dir):\n",
    "            continue\n",
    "\n",
    "        # List and filter log files\n",
    "        log_files = [\n",
    "            os.path.join(session_dir, fname)\n",
    "            for fname in os.listdir(session_dir)\n",
    "            if pattern in fname and fname.endswith('.tsv')\n",
    "        ]\n",
    "\n",
    "        valid_logs = []\n",
    "        performance_scores = []\n",
    "\n",
    "        # Filter logs by length (expecting 48 trials)\n",
    "        for log_path in log_files:\n",
    "            df = pd.read_csv(log_path, sep='\\t')\n",
    "            if len(df) != 48:\n",
    "                continue\n",
    "            valid_logs.append(log_path)\n",
    "            if session == 0:\n",
    "                performance_scores.append(df['Correct'].mean())\n",
    "\n",
    "        print(f'{len(valid_logs)} valid logs found for {subject}, session {session}')\n",
    "\n",
    "        # Select the best baseline run based on performance\n",
    "        if session == 0 and performance_scores:\n",
    "            best_idx = np.argmax(performance_scores)\n",
    "            valid_logs = [valid_logs[best_idx]]\n",
    "\n",
    "        # Process valid log files\n",
    "        for run_idx, log_path in enumerate(valid_logs):\n",
    "            df = pd.read_csv(log_path, sep='\\t')\n",
    "            percent_correct = df['Correct'].mean()\n",
    "            run = 0 if session == 0 else run_idx + 1\n",
    "\n",
    "            results.append({\n",
    "                'subject': subject,\n",
    "                'session': session,\n",
    "                'run': run,\n",
    "                'percent_correct': percent_correct\n",
    "            })\n",
    "\n",
    "# Save results to TSV\n",
    "df_output = pd.DataFrame(results)\n",
    "df_output.to_csv(output_file, sep='\\t', index=False)\n",
    "\n",
    "print(f\"\\nBehavioral data written to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Load data and get summary stats\n",
    "\n",
    "data = pd.read_csv('E:/MeMoSLAP/data/behav_data.tsv', sep='\\t')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-06T11:53:13.227694500Z",
     "start_time": "2025-05-06T11:53:13.209146200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "    subject  session  run  percent_correct\n1  sub-2000        1    1         0.541667\n2  sub-2000        1    2         0.645833\n3  sub-2000        1    3         0.729167\n4  sub-2000        1    4         0.666667\n5  sub-2000        2    1         0.541667",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject</th>\n      <th>session</th>\n      <th>run</th>\n      <th>percent_correct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>sub-2000</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.541667</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>sub-2000</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0.645833</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>sub-2000</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0.729167</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>sub-2000</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0.666667</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>sub-2000</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0.541667</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subdata = data[data['subject'].isin(subjects) & data['session'].isin([1, 2])]\n",
    "subdata.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-06T11:54:04.915259700Z",
     "start_time": "2025-05-06T11:54:04.891260900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean and SD for each session:\n",
      "   session   mean   std\n",
      "0      100  61.21  8.84\n",
      "1      200  62.42  8.35\n",
      "\n",
      "Overall: 61.81 +- 8.5\n"
     ]
    }
   ],
   "source": [
    "mean_over_runs = subdata.groupby(['subject', 'session'])['percent_correct'].mean().reset_index()\n",
    "\n",
    "# Calculate the mean and SD for each session across subjects\n",
    "mean_sd_per_session = mean_over_runs.groupby('session')['percent_correct'].agg(['mean', 'std']).reset_index()\n",
    "print(\"Mean and SD for each session:\")\n",
    "print(round(mean_sd_per_session*100,2))\n",
    "\n",
    "# Calculate the overall mean and SD across all subjects and sessions\n",
    "overall_mean = mean_over_runs['percent_correct'].mean()\n",
    "overall_sd = mean_over_runs['percent_correct'].std()\n",
    "print(f\"\\nOverall: {round(overall_mean*100,2)} +- {round(overall_sd*100,2)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-06T11:54:35.841106400Z",
     "start_time": "2025-05-06T11:54:35.828120500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Source        SS  ddof1  ddof2        MS         F     p-unc  \\\n",
      "0        session  0.005528      1     18  0.005528  0.411594  0.529247   \n",
      "1            run  0.027972      3     54  0.009324  1.061054  0.373320   \n",
      "2  session * run  0.002901      3     54  0.000967  0.193258  0.900545   \n",
      "\n",
      "   p-GG-corr       ng2       eps  \n",
      "0   0.529247  0.003047  1.000000  \n",
      "1   0.368189  0.015228  0.870514  \n",
      "2   0.840180  0.001601  0.717662  \n"
     ]
    }
   ],
   "source": [
    "# Control analysis: Performance by run / session\n",
    "\n",
    "# 2x4 repeated measures ANOVA\n",
    "anova_results = pg.rm_anova(\n",
    "    dv='percent_correct',\n",
    "    within=['session', 'run'],\n",
    "    subject='subject',\n",
    "    data=subdata,\n",
    "    detailed=True\n",
    ")\n",
    "\n",
    "print(anova_results)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-06T15:17:09.837913400Z",
     "start_time": "2025-05-06T15:17:09.781141500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# Control analyses: order of stimuli\n",
    "\n",
    "nses = 1\n",
    "\n",
    "# Initialize the performance arrays (4 columns for the 4 runs)\n",
    "perf_first = np.full((len(subjects), 4), np.nan)\n",
    "perf_second = np.full((len(subjects), 4), np.nan)\n",
    "perf_before = np.full((len(subjects), 4), np.nan)\n",
    "perf_after = np.full((len(subjects), 4), np.nan)\n",
    "\n",
    "# Iterate through the subjects\n",
    "for sc, s in enumerate(subjects):\n",
    "\n",
    "    # Construct the log file path for the subject and session\n",
    "    subject_folder = os.path.join(src_dir, f'{s}_ses-task')\n",
    "    logfile_pattern = f'{s}_tDCS_TWMD_ses-{nses:02d}_run'\n",
    "\n",
    "    # Find all the matching log files in the folder (4 runs expected)\n",
    "    logfile = [f for f in os.listdir(subject_folder) if logfile_pattern in f and f.endswith('.tsv')]\n",
    "\n",
    "    # Ensure there are exactly 4 runs (this is important for the correct indexing)\n",
    "    if len(logfile) != 4:\n",
    "        print(f\"Warning: Expected 4 runs for subject {s}, but found {len(logfile)}.\")\n",
    "        continue  # Skip this subject if the number of runs is not 4\n",
    "\n",
    "    # Iterate through the runs (assuming there are exactly 4 runs)\n",
    "    for r, lf_name in enumerate(logfile):\n",
    "        # Construct the full path of the log file\n",
    "        lf_path = os.path.join(subject_folder, lf_name)\n",
    "\n",
    "        # Read the TSV file into a pandas DataFrame\n",
    "        sublog = pd.read_csv(lf_path, sep='\\t')\n",
    "\n",
    "        # Calculate the performance values based on the conditions\n",
    "        perf_first[sc, r] = sublog[sublog['Target Stimulus'] == 1]['Correct'].mean()\n",
    "        perf_second[sc, r] = sublog[sublog['Target Stimulus'] == 2]['Correct'].mean()\n",
    "        perf_before[sc, r] = sublog[sublog['Stimulus 3'] == 'T']['Correct'].mean()\n",
    "        perf_after[sc, r] = sublog[sublog['Stimulus 3'] == 'F']['Correct'].mean()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-06T15:13:47.177943300Z",
     "start_time": "2025-05-06T15:13:46.482016700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Subject    Time  Memory  Performance\n",
      "0        1  Before   First     0.708333\n",
      "1        2   After   First     0.562500\n",
      "2        3  Before  Second     0.656250\n",
      "3        4   After  Second     0.614583\n",
      "4        5  Before   First     0.437500\n"
     ]
    }
   ],
   "source": [
    "# Assuming these are your performance data\n",
    "perf_before = perf_before.mean(axis=1)  # Replace with actual data\n",
    "perf_after = perf_after.mean(axis=1)\n",
    "perf_first = perf_first.mean(axis=1)\n",
    "perf_second = perf_second.mean(axis=1)\n",
    "\n",
    "# Create a DataFrame in long format\n",
    "df = pd.DataFrame({\n",
    "    'Subject': [i+1 for i in range(19)] * 4,  # Repeat subject 4 times for each condition\n",
    "    'Time': ['Before', 'After', 'Before', 'After'] * 19,  # Time condition for each subject\n",
    "    'Memory': ['First', 'First', 'Second', 'Second'] * 19,  # Memory condition for each subject\n",
    "    'Performance': list(perf_before) + list(perf_after) + list(perf_first) + list(perf_second)\n",
    "})\n",
    "\n",
    "# Check if the data looks okay\n",
    "print(df.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-06T15:13:48.838644800Z",
     "start_time": "2025-05-06T15:13:48.826107900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Source        SS  ddof1  ddof2        MS         F     p-unc  \\\n",
      "0           Time  0.001462      1     18  0.001462  0.158875  0.694883   \n",
      "1         Memory  0.014854      1     18  0.014854  1.647013  0.215643   \n",
      "2  Time * Memory  0.004477      1     18  0.004477  2.245703  0.151319   \n",
      "\n",
      "   p-GG-corr       ng2  eps  \n",
      "0   0.694883  0.001576  1.0  \n",
      "1   0.215643  0.015788  1.0  \n",
      "2   0.151319  0.004812  1.0  \n"
     ]
    }
   ],
   "source": [
    "# Perform a repeated measures ANOVA\n",
    "anova = pg.rm_anova(dv='Performance', within=['Time', 'Memory'], subject='Subject', data=df, detailed=True)\n",
    "\n",
    "# Show the results\n",
    "print(anova)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-06T15:13:50.825445800Z",
     "start_time": "2025-05-06T15:13:50.774159Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
